## Results with deepseek-ai/DeepSeek-R1-Distill-Qwen-7B

![image](results_7b.png)

We evaluate L1-Exact-7B and L1-Max-7B. For baselines, we compare S1, and the original DeepSeek-R1-Distill-Qwen-7B. Note, because of computational cost, we only train L1 models on max 4K context length, while Deepseek-R1-Distill-Qwen-7B has 32K context length.